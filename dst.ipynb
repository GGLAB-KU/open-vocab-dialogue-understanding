{"cells":[{"cell_type":"markdown","metadata":{"id":"3_QL66eLXOIp"},"source":["# Initialization"]},{"cell_type":"markdown","metadata":{},"source":["## Setup Jupyter"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"application/javascript":"if (!(\"Notification\" in window)) {\n    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n    Notification.requestPermission(function (permission) {\n        if(!('permission' in Notification)) {\n            Notification.permission = permission;\n        }\n    })\n}\n","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["%load_ext jupyternotify"]},{"cell_type":"markdown","metadata":{"id":"Pc9j0t-9iIFF"},"source":["## Constants"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":331,"status":"ok","timestamp":1689842478484,"user":{"displayName":"Abdulfattah Safa","userId":"07397629325699666682"},"user_tz":-180},"id":"3auAt957YnaS"},"outputs":[],"source":["use_colab = False\n","use_api = False\n","update_prediction_files = False\n","predict_domains = False\n","predict_user_state_slots = True\n","predict_user_requested_slots = True\n","predict_mismatches = False\n","prediction_level = 'TURN' #TURN or DIALOGUE\n","prompt_type = 'TASK' # QA or TASK\n","predict_dontcare_slots = True\n","use_ontology  = False\n","use_domain_description = False\n","dataset_driver = 'USER' #USER or SYSTEM\n","dataset_driver = 'SYSTEM' #USER or SYSTEM\n","overwrite_predictions = False  # works for both domains and slots"]},{"cell_type":"markdown","metadata":{"id":"AOuUwXXriMuF"},"source":["## Global Directories"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9056,"status":"ok","timestamp":1689842487997,"user":{"displayName":"Abdulfattah Safa","userId":"07397629325699666682"},"user_tz":-180},"id":"k8ZhLM5BYZpd","outputId":"b826cd35-0763-49c0-a524-7d33365e484d"},"outputs":[],"source":["if use_colab:\n","  !pip install bardapi\n","  !pip install openai\n","  import sys\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  root_dir = '/content/drive/MyDrive/Colab/tod-nlu'\n","  dataset_dir = '/content/drive/MyDrive/Colab/datasets/MultiWOZ_2.4/'\n","  sys.path.insert(0,root_dir)\n","  %cd {root_dir}\n","else:\n","  root_dir = '.'\n","  dataset_dir = '../datasets/MultiWOZ2.4/data/MULTIWOZ2.4/'"]},{"cell_type":"markdown","metadata":{"id":"oIqAmXLZiYHc"},"source":["## Modules"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1689842487998,"user":{"displayName":"Abdulfattah Safa","userId":"07397629325699666682"},"user_tz":-180},"id":"vDCFSAqdXOIs"},"outputs":[{"name":"stdout","output_type":"stream","text":["['train_id', 'value_time']\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /home/asafa/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /home/asafa/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import json\n","import os\n","import csv\n","from Dataset import Dataset\n","from ChatBot import ChatBot\n","from multiwoz_utils import MultiWOZ"]},{"cell_type":"markdown","metadata":{"id":"wEyQVs8fib-i"},"source":["## Constants and Global Variables"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":316,"status":"ok","timestamp":1689842995362,"user":{"displayName":"Abdulfattah Safa","userId":"07397629325699666682"},"user_tz":-180},"id":"bw-DkfLTXOIu"},"outputs":[],"source":["dataset_split=\"test\"\n","model = 'CHATGPT'\n","sub_model = 'gpt-4o'\n","\n","response_format = 'json'\n","sub_model_name = sub_model.replace('/','-')\n","model_name = model.replace('/', '-')\n","\n","dataset_name = 'SGD'\n","dataset_name = 'MultiWOZ'\n","\n","dataset_type = 'SGD'\n","dataset_type = 'MWZ'\n","\n","test_dialogue_lower_index = 0 #\n","test_dialogue_upper_index = 1001"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1689842487999,"user":{"displayName":"Abdulfattah Safa","userId":"07397629325699666682"},"user_tz":-180},"id":"Nsa8jcv-XQUH"},"outputs":[],"source":["# directories\n","data_dir = os.path.join(root_dir, 'data', dataset_name)\n","log_dir = os.path.join(root_dir, 'debug', dataset_name)\n","os.makedirs(log_dir, exist_ok=True)\n","metadata_file_path = os.path.join(data_dir, 'metadata.json')\n","\n","# files\n","# Make sure to delete the predicted_slots file if you need to predict all slots\n","prompt_template_file_path = os.path.join(root_dir,'prompt_templates.json')\n","# construct the predicted dialogue file path\n","if not use_ontology:\n","    predicted_dialogues_file_path = os.path.join(\n","    data_dir, dataset_split, model_name+'-'+sub_model_name+'_'+prompt_type+'_'+prediction_level+'_'+'dialogues.json')\n","else:\n","     predicted_dialogues_file_path = os.path.join(data_dir, dataset_split, model_name+'-'+sub_model_name+'_'+prompt_type+'_'+prediction_level+'_'+'with-ontology'+'_'+'dialogues.json')\n","#predicted_dialogues_file_path = os.path.join(data_dir, dataset_split,'CHATGPT-gpt-4-turbo-preview_TASK_TURN_without-domain-fixes_dialogues.json')\n","\n","annotated_dialogues_file_path = os.path.join(\n","    data_dir, dataset_split, model+'-'+sub_model_name+'_'+'annotated_dialogues.json')\n","mismatched_domains_file_path = os.path.join(\n","    root_dir, 'debug/mismatched_domains.txt')\n","mismatched_state_slots_file_path = os.path.join(\n","    root_dir, 'debug/mismatched_state_slots.txt')\n","additional_state_slots_file_path = os.path.join(\n","    root_dir, 'debug/additional_state_slots.psv')\n","missing_requested_slots_file_path = os.path.join(\n","    root_dir, 'debug/missing_requested_slots.txt')\n","additional_requested_slots_file_path = os.path.join(\n","    root_dir, 'debug/additional_requested_slots.psv')\n","slot_value_pool_file_path = os.path.join(data_dir, 'slot_value_pool.psv')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1689842487999,"user":{"displayName":"Abdulfattah Safa","userId":"07397629325699666682"},"user_tz":-180},"id":"dmCBEGNMXOIv"},"outputs":[],"source":["if use_api:\n","    chatBot = ChatBot(model, sub_model, response_format, prompt_template_file_path, log_dir, debug=False)"]},{"cell_type":"markdown","metadata":{"id":"nfwNY98CXOIz"},"source":["# Load ground truth data"]},{"cell_type":"markdown","metadata":{"id":"BZNEMRY0XOIz"},"source":["Load datasets"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12173,"status":"ok","timestamp":1689842500164,"user":{"displayName":"Abdulfattah Safa","userId":"07397629325699666682"},"user_tz":-180},"id":"9ylAoYMqXOIz","outputId":"57226c22-4b46-4a4f-c8f2-4218030af9be"},"outputs":[{"name":"stdout","output_type":"stream","text":["parsing domain Restaurant\n","parsing domain Attraction\n","parsing domain hotel\n","parsing domain taxi\n","parsing domain train\n","parsing domain Bus\n","parsing domain Hospital\n","parsing domain Police\n","reading all dialoge\n","training data size:  8438\n","development data size:  1000\n","testing data size:  1000\n","Finished reading the ./data/MultiWOZ/slot_value_pool.psv\n","Number of entries in ./data/MultiWOZ/slot_value_pool.psv is 0\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n"]},{"name":"stdout","output_type":"stream","text":["Dumping ./data/MultiWOZ/slot_value_pool.psv\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n","Dumping ./data/MultiWOZ/slot_value_pool.psv\n"]}],"source":["dataset = Dataset(dataset_type, metadata_file_path, dataset_dir)\n","dataset.parse()\n","\n","# to be refactored\n","dataset_utils = MultiWOZ(domains=dataset.domains.keys(), slots=dataset.slots, slot_value_pool_file_path=slot_value_pool_file_path)"]},{"cell_type":"markdown","metadata":{"id":"XH_dbZ3CXOIz"},"source":["# Predict data"]},{"cell_type":"markdown","metadata":{},"source":["## Load Previous Predicitons"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"2isSWw86XOIz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset Dialogues size  1000\n","Parsing dialogue file ./data/MultiWOZ/test/CHATGPT-gpt-4o_TASK_TURN_dialogues.json\n","Predicted Dialogues size  1000\n"]}],"source":["if os.path.isfile(predicted_dialogues_file_path):\n","    with open(predicted_dialogues_file_path, 'r') as file:\n","        predicted_dialogues = json.load(file)\n","else:\n","        predicted_dialogues = {}\n","dataset_dialogues = dataset.get_split_data(split=dataset_split)\n","\n","print('Dataset Dialogues size ', len(dataset_dialogues))\n","print(f'Parsing dialogue file {predicted_dialogues_file_path}')\n","print('Predicted Dialogues size ', len(predicted_dialogues))"]},{"cell_type":"markdown","metadata":{"id":"2isSWw86XOIz"},"source":["## Predict Domains"]},{"cell_type":"markdown","metadata":{},"source":["### Load mismatched domains from files"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["344  entries were found in  ./debug/mismatched_domains.txt\n"]}],"source":["#### read mismatched domains files ###\n","try:\n","    with open(mismatched_domains_file_path, 'r') as mismatched_domains_file:\n","        mismatched_domains_ids = [row.split('|')[0].strip() for row in mismatched_domains_file]\n","except:\n","    mismatched_domains_ids = []\n","print(len(mismatched_domains_ids), ' entries were found in ',\n","      mismatched_domains_file_path)"]},{"cell_type":"markdown","metadata":{},"source":["### Predict Domains"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"sfF2cOGeXOI0"},"outputs":[],"source":["processed_dialogue_index = -1\n","if use_api and predict_domains:\n","    for dialogue in dataset_dialogues:\n","        dialogue_turns = []\n","        dialogue_speakers = []\n","        predict_dialogue_domains = False\n","        processed_dialogue_index+=1\n","        print('Number of processed dialogues so far = ',processed_dialogue_index)\n","        if processed_dialogue_index<test_dialogue_lower_index:\n","            continue\n","        if processed_dialogue_index>test_dialogue_upper_index:\n","            break\n","        for turn in dataset_dialogues[dialogue]:\n","            turn_id = dialogue+'-'+turn\n","            text = dataset_dialogues[dialogue][turn]['text']\n","            speaker = dataset_dialogues[dialogue][turn]['speaker']\n","            dialogue_turns.append(text)\n","            dialogue_speakers.append(speaker)\n","            print(turn_id)\n","            if overwrite_predictions:\n","                predict_dialogue_domains = True\n","            elif not dialogue in predicted_dialogues:\n","                predict_dialogue_domains = True\n","            elif predict_mismatches and turn_id in mismatched_domains_ids:\n","                predict_dialogue_domains = True\n","                print(dialogue+'-'+turn, ' found in the mismatched domains file')\n","            elif not overwrite_predictions and 'domains' in predicted_dialogues[dialogue][turn].keys():\n","                print(dialogue+'-'+turn, 'has already predictions')\n","                predict_dialogue_domains = predict_dialogue_domains | False\n","            else:\n","                predict_dialogue_domains = False\n","        \n","        if predict_dialogue_domains:\n","            predicted_domains = chatBot.predict_dialogue_domains(dialogue_turns, dialogue_speakers, dataset.domains, prediction_level, use_domain_description)\n","            predicted_dialogues[dialogue] = {}\n","            for turn_index in predicted_domains:\n","                # check if additional turns are back                \n","                if turn_index in dataset_dialogues[dialogue].keys():\n","                    predicted_dialogues[dialogue][turn_index]={}\n","                    predicted_dialogues[dialogue][turn_index]['text'] = dataset_dialogues[dialogue][turn_index]['text']\n","                    predicted_dialogues[dialogue][turn_index]['speaker'] = dataset_dialogues[dialogue][turn_index]['speaker']\n","                    predicted_dialogues[dialogue][turn_index]['history'] = dataset_dialogues[dialogue][turn_index]['history']\n","\n","                    turn_predicted_domains = predicted_domains[turn_index]\n","                    # filter domains\n","                    if isinstance(turn_predicted_domains, str):\n","                        turn_predicted_domains = [turn_predicted_domain]\n","                    for turn_predicted_domain in turn_predicted_domains:\n","                        if not turn_predicted_domain in dataset_utils.domains:\n","                            print('Predicted domain ', turn_predicted_domain,' is not of the defined domain list')\n","                            turn_predicted_domains.remove(turn_predicted_domain)\n","                    predicted_dialogues[dialogue][turn_index]['domains']=turn_predicted_domains\n","                else:\n","                    print('Turn with index ', turn_index,' couldn\\'t be found in the dialogue ', dialogue)\n","            \n","            # fill out the turns with no predicted domains\n","        for turn in dataset_dialogues[dialogue]:\n","            if not turn in predicted_dialogues[dialogue]:\n","                predicted_dialogues[dialogue][turn] = {}\n","                predicted_dialogues[dialogue][turn]['text'] = dataset_dialogues[dialogue][turn]['text']\n","                predicted_dialogues[dialogue][turn]['speaker'] = dataset_dialogues[dialogue][turn]['speaker']\n","                predicted_dialogues[dialogue][turn]['history'] = dataset_dialogues[dialogue][turn]['history']\n","            if not 'domains' in predicted_dialogues[dialogue][turn]:\n","                predicted_dialogues[dialogue][turn]['domains']=[]"]},{"cell_type":"markdown","metadata":{},"source":["## Predict Slots"]},{"cell_type":"markdown","metadata":{},"source":["### Load mismatched data from files"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2161  entries were found in  ./debug/mismatched_state_slots.txt\n","0  entries were found in  ./debug/missing_requested_slots.txt\n"]}],"source":["#### read mismatched slots files ###\n","try:\n","    with open(mismatched_state_slots_file_path, 'r') as mismatched_state_slots_file:\n","        mismatched_state_slot_ids = [row.split('|')[0] for row in mismatched_state_slots_file]\n","except:\n","    mismatched_state_slot_ids = []\n","print(len(mismatched_state_slot_ids), ' entries were found in ',\n","      mismatched_state_slots_file_path)\n","\n","try:\n","    with open(missing_requested_slots_file_path, 'r') as missing_requested_slots_file:\n","        missing_requested_slots_ids = [row.split('|')[0] for row in missing_requested_slots_file]\n","except:\n","    missing_requested_slots_ids = []\n","print(len(missing_requested_slots_ids), ' entries were found in ',\n","      missing_requested_slots_file_path)\n","#### finished reading mismatched slots files ###"]},{"cell_type":"markdown","metadata":{},"source":["### Predict Slots"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def predict_turn_slots_as_qa(turns, speakers, domain, schema_slots, dialogue_state):\n","    # 1. extract the turn slots\n","    predicted_slots = {}\n","    dontcare_value_found = False\n","    last_turn_speaker = speakers[-1]\n","    # extract the possible values\n","    turn_extracted_slots = chatBot.extract_turn_entities(\n","        turn=turns[-1], prediction_level='TURN')\n","    domain_slots = schema_slots[domain]\n","\n","    # check if dontcare slot found\n","    if 'DONTCARE' in turn_extracted_slots and len(turn_extracted_slots['DONTCARE']) > 0:\n","        dontcare_value_found = True\n","\n","    for slot in domain_slots:\n","        slot_category = domain_slots[slot]['category']\n","        possible_slot_values = set()\n","        # add possible slot values from the same slot type from dialogue state\n","        # to cover the cases where the slot value was proposed by the system\n","        for speaker in dialogue_state:\n","            for state_domain in dialogue_state[speaker]:\n","                for state_slot in dialogue_state[speaker][state_domain]:\n","                    if slot_category == schema_slots[state_domain][state_slot]['category']:\n","                        if isinstance(dialogue_state[speaker][state_domain][state_slot], list):\n","                            possible_slot_values.update(\n","                                dialogue_state[speaker][state_domain][state_slot])\n","                        else:\n","                            possible_slot_values.add(dialogue_state[speaker][state_domain][state_slot])\n","\n","        if slot_category in turn_extracted_slots and len(turn_extracted_slots[slot_category]) > 0:\n","            if slot_category in turn_extracted_slots and len(turn_extracted_slots[slot_category]) > 0:\n","                extracted_slot_values = turn_extracted_slots[slot_category]\n","            else:\n","                extracted_slot_values = []\n","            \n","            if predict_dontcare_slots and dontcare_value_found and last_turn_speaker == 'USER':\n","                extracted_slot_values.append('dontcare: USER explicitly said he has no preference for the slot value.')\n","                if 'dontcare' in extracted_slot_values:\n","                    extracted_slot_values.remove('dontcare')\n","            print('extracted_slot_values: ', extracted_slot_values)\n","            try:\n","                possible_slot_values.update(extracted_slot_values)\n","            except:\n","                print('ERROR: extracted_slot_values is not valid list. ', extracted_slot_values)\n","\n","            predicted_slot_value = chatBot.choose_slot_value(\n","                slot, turns=turns, speakers=speakers, domain=domain, domain_slots=domain_slots, possible_values=possible_slot_values)\n","            if predicted_slot_value == 'None':\n","                continue\n","\n","            predicted_slots[slot] = predicted_slot_value\n","    dialogue_state[speakers[-1]][domain].update(predicted_slots)\n","\n","    return predicted_slots, dialogue_state"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def predict_dialogue_slots(dialogue, domains, dataset_slots, use_slots_possible_values, prediction_type):\n","    \n","    if prediction_type == 'TASK':\n","        turns = []\n","        speakers = []\n","        \n","        for turn in dialogue:\n","            turns.append(dialogue[turn]['text'])\n","            speakers.append(dialogue[turn]['speaker'])\n","\n","        for domain in domains:\n","            domain_slots = dataset_slots[domain]\n","            dialogue_domain_slots = chatBot.predict_dialogue_slots(turns, speakers, domain, domain_slots=domain_slots,use_slots_possible_values=use_slots_possible_values, prediction_level=prediction_level)\n","            for turn_index in dialogue_domain_slots:\n","                turn_domain_state_slots = {}\n","                turn_domain_requested_slots = []\n","                if not turn_index in dialogue or not isinstance(dialogue_domain_slots[turn_index], dict):\n","                    print('Warning: predicted slots have additional turn index ', turn_index)\n","                    continue\n","                if not isinstance(dialogue_domain_slots[turn_index], dict):\n","                    print('Warning: invalud predicted slots ', dialogue_domain_slots[turn_index])\n","                    continue\n","                \n","                for slot in dialogue_domain_slots[turn_index]:\n","                    if dialogue_domain_slots[turn_index][slot] == '?':\n","                        turn_domain_requested_slots.append(slot)\n","                    else:\n","                        turn_domain_state_slots[slot] = dialogue_domain_slots[turn_index][slot]\n","                \n","                if not domain in dialogue[turn_index]['domains']:\n","                    dialogue[turn_index]['domains'][domain] = {}\n","                dialogue[turn_index]['domains'][domain]['slots'] = turn_domain_state_slots\n","                dialogue[turn_index]['domains'][domain]['requested_slots'] = turn_domain_requested_slots\n","            \n","    \n","    elif prediction_type == 'QA':\n","        print('dialogue domains to predict = ', domains)\n","        turns = []\n","        speakers = []\n","        dialogue_state = {}\n","        for turn in dialogue:\n","            speaker = dialogue[turn]['speaker']\n","            if not speaker in dialogue_state:\n","                dialogue_state[speaker] = {}\n","            turns.append(dialogue[turn]['text'])\n","            speakers.append(dialogue[turn]['speaker'])\n","            turn_domains = dialogue[turn]['domains']\n","            print(f'Turn domains {turn_domains}')\n","            for domain in turn_domains:\n","                print('domain = ', domain)\n","                print(f'working on {turn}-{domain}')\n","                if not domain in domains:\n","                    continue\n","                if not domain in dialogue_state[speaker]:\n","                    dialogue_state[speaker][domain] = {}\n","                turn_predicted_slots, dialogue_state = predict_turn_slots_as_qa(turns = turns, speakers= speakers, domain=domain, schema_slots=dataset.slots, dialogue_state=dialogue_state)\n","                dialogue[turn]['domains'][domain]['slots'] = turn_predicted_slots\n","    \n","    #print('dialogue = ', dialogue)\n","    return dialogue"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["if use_api and (predict_user_state_slots or predict_user_requested_slots):\n","    processed_dialogue_index = -1\n","    for dialogue in predicted_dialogues:\n","        dialogue_turns = []\n","        dialogue_speakers = []\n","        dialogue_domains = {}\n","        processed_dialogue_index += 1\n","        dialogue_domains_to_predict = set()\n","        dialogue_domain_tracker = set()\n","\n","        print('Number of processed dialogues so far = ', processed_dialogue_index)\n","        if processed_dialogue_index < test_dialogue_lower_index:\n","            continue\n","        if processed_dialogue_index > test_dialogue_upper_index:\n","            break\n","\n","        for turn in predicted_dialogues[dialogue]:\n","            print(dialogue+':'+turn)\n","            speaker = predicted_dialogues[dialogue][turn]['speaker']\n","            text = predicted_dialogues[dialogue][turn]['text']\n","            dialogue_turns.append(text)\n","            dialogue_speakers.append(speaker)\n","            # set the domains to predict for #\n","            turn_domains = predicted_dialogues[dialogue][turn]['domains']\n","            \n","            # append the dataset domains #\n","            if isinstance(turn_domains , list):\n","                dialogue_domain_tracker.update(turn_domains)\n","            else:\n","                dialogue_domain_tracker.update(list(turn_domains.keys()))\n","            \n","            # add the datasets domains\n","            '''dataset_domains = dataset_dialogues[dialogue][turn]['domains']\n","            for dataset_domain in dataset_domains:\n","                if dataset_domain not in dialogue_domain_tracker:\n","                    turn_domains[dataset_domain] = {}\n","                    turn_domains[dataset_domain]['source'] = 'dataset'''\n","            dialogue_domains[turn] = turn_domains\n","\n","            # Check which domain to predict\n","            if overwrite_predictions or isinstance(turn_domains , list):\n","                predicted_dialogues[dialogue][turn][\"domains\"]={}\n","                for turn_domain in turn_domains:\n","                    predicted_dialogues[dialogue][turn]['domains'][turn_domain] = {}\n","                    predicted_dialogues[dialogue][turn]['domains'][turn_domain]['slots'] = {}\n","                    predicted_dialogues[dialogue][turn]['domains'][turn_domain]['requested_slots'] = {}\n","                dialogue_domains_to_predict.update(turn_domains)\n","            else:\n","                # loop over the turn domains\n","                for turn_domain in turn_domains:\n","                    domain_id = dialogue+'-'+turn+'-'+turn_domain\n","                    print('Working on: ', domain_id)\n","                    predict_domain_slots = False\n","                    if not 'slots' in predicted_dialogues[dialogue][turn][\"domains\"][turn_domain]:\n","                        predict_domain_slots = True\n","                    elif predict_mismatches and domain_id in mismatched_state_slot_ids:\n","                        print(domain_id,' is found in the mismatched slots file. Will be predicted')\n","                        predict_domain_slots = True\n","                    elif predict_mismatches and domain_id in missing_requested_slots_ids:\n","                        print(domain_id,' is found in the missing slots file. Will be predicted')\n","                        predict_domain_slots = True\n","                    elif not 'requested_slots' in predicted_dialogues[dialogue][turn][\"domains\"][turn_domain]:\n","                        predict_domain_slots = True\n","                    else:\n","                        predict_domain_slots = False\n","                        print(domain_id, ' has already predicted slots')\n","\n","                    if predict_domain_slots:\n","                        dialogue_domains_to_predict.add(turn_domain)\n","        \n","        # initiate the slots to avoid predicting the turn  domain again later\n","        for dialogue_domain in dialogue_domains_to_predict:\n","            for turn in  predicted_dialogues[dialogue]:\n","                if dialogue_domain in predicted_dialogues[dialogue][turn]['domains']:\n","                    predicted_dialogues[dialogue][turn]['domains'][dialogue_domain]['slots'] = {}\n","                    predicted_dialogues[dialogue][turn]['domains'][dialogue_domain]['requested_slots'] = []\n","\n","        # start predicting the slots\n","        print('Predicting the slots for ', dialogue)\n","        dialogue = predict_dialogue_slots(dialogue=predicted_dialogues[dialogue], domains = dialogue_domains_to_predict, dataset_slots = dataset.slots, use_slots_possible_values=use_ontology, prediction_type=prompt_type)\n","            "]},{"cell_type":"markdown","metadata":{},"source":["## Update Prediction File"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["if update_prediction_files:\n","    with open(predicted_dialogues_file_path, 'w') as file:\n","        json.dump(predicted_dialogues, file, indent=4)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
